# Describe the source
a2.sources=r1
a2.sinks=k1 k2
a2.channels=c1 c2

# Describe/configure the source
a2.sources.r1.type=avro
# 任何主机发送过来的信息都可以采集
a2.sources.r1.bind=0.0.0.0
a2.sources.r1.port=22223
a2.sources.r1.selector.type=replicating

# Describe the sink(logger是直接打印到控制台)
a2.sinks.k1.type=hdfs
# 目录不用自己创建, 会自动创建
a2.sinks.k1.hdfs.path=/flume/event/example2/%y%m%d
a2.sinks.k1.hdfs.filePrefix=Example2-
a2.sinks.k1.hdfs.fileType=DataStream
a2.sinks.k1.hdfs.writeFormat=Text
#是否轮转生成新的hdfs文件
a2.sinks.k1.hdfs.round=true
#每一分钟轮转一次, 生成新的文件, 但是没有接收到event的话是不会每分钟都生成新的文件的
a2.sinks.k1.hdfs.roundValue=1
a2.sinks.k1.hdfs.roundUnit=minute
# 使用本地时间戳
a2.sinks.k1.hdfs.useLocalTimeStamp=true

# Describe the sink, 表要事先创建
a2.sinks.k2.type=hbase
a2.sinks.k2.table=flume_example02
a2.sinks.k2.columnFamily=cf1
a2.sinks.k2.serializer=org.apache.flume.sink.hbase.RegexHbaseEventSerializer

# Use a channel which buffers events in memory
a2.channels.c1.type=file
a2.channels.c1.checkpointDir=/tmp/flume/example2_1/checkpoint
a2.channels.c1.dataDirs=/tmp/flume/example2_1/data

# Use a channel which buffers events in memory
a2.channels.c2.type=file
a2.channels.c2.checkpointDir=/tmp/flume/example2_2/checkpoint
a2.channels.c2.dataDirs=/tmp/flume/example2_2/data

# Bind the source and sink to the channel
a2.sources.r1.channels=c1 c2
a2.sinks.k1.channel=c1
a2.sinks.k2.channel=c2

#################################################
# 该配置与test-example2-tier1-conf.properties一起使用, 参看test-example2-tier1-conf.properties中的注释
##########################################################