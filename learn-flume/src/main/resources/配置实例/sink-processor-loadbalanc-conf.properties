# Describe the source
a1.sources=r1
a1.sinks=k1 k2
a1.channels=c1

# Describe/configure the source
a1.sources.r1.type=exec
a1.sources.r1.command = tail -F /home/hadoop/data/file-exec.log

a1.sinkgroups = g1
a1.sinkgroups.g1.sinks = k1 k2
a1.sinkgroups.g1.processor.type = load_balance
a1.sinkgroups.g1.processor.selector=random

# Describe the sink
a1.sinks.k1.type=hdfs
# /flume/event/目录需要先创建, hadoop fs -mkdir -p /flume/event/
a1.sinks.k1.hdfs.path=/flume/event/%y%m%d
a1.sinks.k1.hdfs.filePrefix=sink-processor-loadbalance-
#是否轮转生成新的hdfs文件
a1.sinks.k1.hdfs.round=true
#每一分钟轮转一次, 生成新的文件, 但是没有接收到event的话是不会每分钟都生成新的文件的
a1.sinks.k1.hdfs.roundValue=1
a1.sinks.k1.hdfs.roundUnit=minute
# 使用本地时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp=true
a1.sinks.k1.hdfs.fileType=DataStream
a1.sinks.k1.hdfs.writeFormat=Text

# Describe the sink
a1.sinks.k2.type=hbase
a1.sinks.k2.table=flume_test03
a1.sinks.k2.columnFamily=cf1
a1.sinks.k2.serializer=org.apache.flume.sink.hbase.RegexHbaseEventSerializer

# Use a channel which buffers events in memory
a1.channels.c1.type=memory
a1.channels.c1.capacity=1000
a1.channels.c1.transactionCapacity=100

# Bind the source and sink to the channel
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1
a1.sinks.k2.channel=c1

#################################################
# 在Hbase中创建表flume_test03, sh hbase shell
# create 'flume_test03', 'cf1'
# 启动agent代理:
# $flume-ng agent -n a1 -f sink-processor-failover-conf.properties
# 对应hdfs,写.tmp临时文件, 写好后改成不带.tmp的文件, 比如: /flume/event/170821/sink-processor-loadbalance-.1503296361279.tmp, 最终变成: /flume/event/170821/sink-processor-loadbalance-.1503296361279
# $ hadoop fs -cat /flume/event/170821/sink-processor-loadbalance-.1503296361279
# test exec source
# test flume
# test flume 2
# hahahaha
# test file channel
# Test hdfs sink
# file roll sink
# 我们发现数据都写到了hdfs中, 我们再向文件中追加数据:
# echo "test loadbalance" >> /home/hadoop/data/file-exec.log
# 而进入hbase, 通过命令: scan 'flume_test03'
#hbase(main):008:0> scan 'flume_test03'
#ROW                                              COLUMN+CELL
#1503296578741-r1d9O8LJ63-0                      column=cf1:payload, timestamp=1503296581920, value=test loadbalance
# 我们发现数据进入到了hbase中
##########################################################