# Describe the source
a1.sources=r1
a1.sinks=k1
a1.channels=c1

# Describe/configure the source
a1.sources.r1.type=exec
a1.sources.r1.command = tail -F /home/hadoop/text.txt

# Describe the sink(logger是直接打印到控制台)
a1.sinks.k1.type=hive
a1.sinks.k1.hive.metastore=thrift://bds-test-004:9083
a1.sinks.k1.hive.database=default
a1.sinks.k1.hive.table=hive_sink
a1.sinks.k1.hive.partition=%Y%m%d,shanghai
a1.sinks.k1.useLocalTimeStamp=true
a1.sinks.k1.round = true
a1.sinks.k1.roundValue = 1
a1.sinks.k1.roundUnit = minute
a1.sinks.k1.serializer = DELIMITED
a1.sinks.k1.serializer.delimiter = ","
a1.sinks.k1.serializer.serdeSeparator = ','
a1.sinks.k1.serializer.fieldnames =id,name
a1.sinks.sink1.hive.txnsPerBatchAsk = 2
a1.sinks.sink1.batchSize = 10

# Use a channel which buffers events in memory
a1.channels.c1.type=memory
a1.channels.c1.capacity=1000
a1.channels.c1.transactionCapacity=100

# Bind the source and sink to the channel
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1

#################################################
# 创建表: 需要分桶并且是orc格式(即定义事务表, 目前hive中只有orc格式的表支持事务表,'transactional'='true'表示是事务表, hive中的事务操作对应的表必须是分桶表, 并且不能是外部表)
# create table hive_sink ( id int , name string )
# partitioned by (stat_date string, province string)
# clustered by (id) into 2 buckets
# stored as orc TBLPROPERTIES('transactional'='true');
# 在hive-site中设置如下参数:
# hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
# hive.compactor.initiator.on = true
# hive.compactor.worker.threads > 0 (eg. 5), 这里设置为hive.compactor.worker.threads=5
# hive.support.concurrency=true
# 将flume lib中的libthrift-0.9.0.jar替换为libthrift-0.9.3.jar版本, 负责启动flume时会报错:NoSuchMethodError: com.facebook.fb303.FacebookService$Client.sendBaseOneway
# 启动agent代理:
# $flume-ng agent -n a1 -f sink-hive-conf.properties
# 文件内容:
#1,zhangsan
#2,lisi
#3,wangwu
#在hive中可以看到数据已经进入了, 创建了分区stat_date=20170821/province=shanghai
#疑问? 当flume端不使用ctrl+c停止服务的话, 在hive中查询该对应表的数据的时候会卡死, 只有使用ctrl+c停止服务, 才能在hive中从表hive_sink中查询出数据
##########################################################