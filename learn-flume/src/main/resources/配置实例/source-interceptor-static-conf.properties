# Describe the source
a1.sources=r1
a1.sinks=k1
a1.channels=c1

# Describe/configure the source
a1.sources.r1.type=exec
a1.sources.r1.command = tail -F /home/hadoop/data/file-exec.log
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = static
a1.sources.r1.interceptors.i1.key = city
a1.sources.r1.interceptors.i1.value = beijing
# 如果报头中已经有该键, 则保留, 不进行替换
a1.sources.r1.interceptors.i1.preserveExisting = true

# Describe the sink(logger是直接打印到控制台)
a1.sinks.k1.type=logger
# Maximum number of bytes of the Event body to log, 默认值是16, 如果使用默认值, 当event比较长时, 会被截断
maxBytesToLog=1024

# Use a channel which buffers events in memory
a1.channels.c1.type=memory
a1.channels.c1.capacity=1000
a1.channels.c1.transactionCapacity=100

# Bind the source and sink to the channel
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1

#################################################
# 启动agent代理:
# $flume-ng agent -n a1 -f source-interceptor-static-conf.properties
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 74 65 73 74 20 65 78 65 63 20 73 6F 75 72 63 65 test exec source }
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 74 65 73 74 20 66 6C 75 6D 65                   test flume }
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 74 65 73 74 20 66 6C 75 6D 65 20 32             test flume 2 }
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 68 61 68 61 68 61 68 61                         hahahaha }
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 74 65 73 74 20 66 69 6C 65 20 63 68 61 6E 6E 65 test file channe }
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 54 65 73 74 20 68 64 66 73 20 73 69 6E 6B       Test hdfs sink }
#17/08/22 21:59:54 INFO sink.LoggerSink: Event: { headers:{city=beijing} body: 66 69 6C 65 20 72 6F 6C 6C 20 73 69 6E 6B       file roll sink }
##########################################################